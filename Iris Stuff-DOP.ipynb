{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592f94c9-fa29-4e44-92ff-a920049859ba",
   "metadata": {},
   "source": [
    "# Classifying IRIS and more, the Data Oriented Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dec9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8005f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pyrsistent import PRecord, field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d7e3d-c106-4848-b45c-3cd89461e029",
   "metadata": {},
   "source": [
    "### Task 2 Redux ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ad4c2-5551-40c5-a1ef-eebde94dbda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD CODE\n",
    "class ML_Dataset():\n",
    "    \"\"\" Should hold our data, targets, predictions, basically X and y...\n",
    "    Should also be able to fill itself, once we need it. \"\"\"\n",
    "    X = None\n",
    "    y = None\n",
    "    y_pred = None\n",
    "\n",
    "    def load_iris(self):        \n",
    "        iris = datasets.load_iris()\n",
    "        self.X = iris[\"data\"][:,3:]  # petal width\n",
    "        self.y = (iris[\"target\"]==2).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a0ab28-e17b-491e-9233-0c8c8551a82e",
   "metadata": {},
   "source": [
    "\n",
    "**Task 2**: Let us exchange the dataset. \n",
    "\n",
    "**Underlying Problem**: We're mixing code and data, or business logic and data. \n",
    "\n",
    "**DO**: The Data Oriented approach is simple, decouple data and business logic, data and code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "408490c7-f23e-4ab5-8f50-bcbfa001acc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74/2515469637.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  m.y = (iris[\"target\"]==2).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "### THE DO Approach\n",
    "class ML_Dataset():\n",
    "    \"\"\" Should hold our data, targets, predictions, basically X and y...\n",
    "    Should also be able to fill itself, once we need it. \"\"\"\n",
    "    X = None\n",
    "    y = None\n",
    "    y_pred = None\n",
    "\n",
    "def load_iris(m: ML_Dataset):        \n",
    "    iris = datasets.load_iris()\n",
    "    m.X = iris[\"data\"][:,3:]  # petal width\n",
    "    m.y = (iris[\"target\"]==2).astype(np.int)\n",
    "    \n",
    "## load old data\n",
    "m = ML_Dataset()\n",
    "load_iris(m)\n",
    "\n",
    "## load something new\n",
    "def load_new(m: ML_Dataset):\n",
    "    m.X=np.array([[1],[2],[3],[4],[5]])\n",
    "    m.y= np.array([1,0,0,1,1])\n",
    "\n",
    "load_new(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad29b1f-ad42-495f-84be-d61c989860a6",
   "metadata": {},
   "source": [
    "### Task 1 Redux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e093f45-ad62-4feb-8b57-71c71424705b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "### OLD CODE\n",
    "class ML_Dataset():\n",
    "    \"\"\" Should hold our data, targets, predictions, basically X and y...\n",
    "    Should also be able to fill itself, once we need it. \"\"\"\n",
    "    X = None\n",
    "    y = None\n",
    "    y_pred = None\n",
    "\n",
    "    def load_iris(self):        \n",
    "        iris = datasets.load_iris()\n",
    "        self.X = iris[\"data\"][:,3:]  # petal width\n",
    "        self.y = (iris[\"target\"]==2).astype(np.int)\n",
    "\n",
    "m = ML_Dataset()\n",
    "m.X = np.linspace(0,3,1000).reshape(-1,1)\n",
    "m.X= 1\n",
    "print(m.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36222937-ed24-45df-bff1-d24afa6d92e1",
   "metadata": {},
   "source": [
    "Here's what we encountered at step 1 last time, X got overwritten because we thought we don't need it anymore.\n",
    "\n",
    "**Task 1**: Let's compare the predictions vs. the old classes.\n",
    "\n",
    "**Underlying Problem**: Stuff is mutable.\n",
    "\n",
    "**DOP Solution**: Use mostly immutable (data) structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc2c7c1-3cd5-49a1-bc89-05b9848b51b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "### NEW DOP Implementation\n",
    "# We're using the module for immutable python pyrsistent here\n",
    "\n",
    "class ML_Dataset(PRecord):\n",
    "    X = field()\n",
    "    y = field()\n",
    "    y_pred = field()\n",
    "    X_new = field()\n",
    "     \n",
    "def load_iris():\n",
    "    iris = datasets.load_iris()\n",
    "    r_1 = ML_Dataset()\n",
    "    r_2=r_1.set(X=iris[\"data\"][:,3:])\n",
    "    r_3=r_2.set(y=iris[\"target\"])\n",
    "    return r_3\n",
    "\n",
    "## Just for one, let's try it out!\n",
    "\n",
    "r = load_iris()\n",
    "r = r.set(X = np.linspace(0,3,1000).reshape(-1,1))\n",
    "\n",
    "r.set(X=\"1\")\n",
    "# print(r.X)\n",
    "# >> [0.        ]...... [0.01201201]\n",
    "## Oh that doesn't work, let's try direct item assignment maybe?\n",
    "r[\"X\"]=1\n",
    "## >> TypeError: 'ML_Dataset' object does not support item assignment\n",
    "# Nice, so now this cannot happen accidentally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a8270-aae3-433e-95b8-45576f02b014",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69589be6-2e78-4d88-9908-5ebc8fb2c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD CODE\n",
    "class ML_CLF():\n",
    "    \"\"\"Should hold the classifier we want to use here,\n",
    "    should also be able to fit and predict. \"\"\"\n",
    "    clf = None\n",
    "    trial_note = \"trial 1\"\n",
    "    \n",
    "    def fit_clf(self, m: ML_Dataset):  \n",
    "        self.clf = svm.SVC(gamma='scale', decision_function_shape='ovo', probability=True)\n",
    "        self.clf.fit(m.X,m.y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "        \n",
    "    def write_preds(self,m):\n",
    "        \"\"\"Writes predictions into an ML_Dataset using this classifier\"\"\"\n",
    "        m.y_pred = self.clf.predict_proba(m.X)\n",
    "\n",
    "#### -------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "### Now let's create another classifier.\n",
    "\n",
    "# Let's print it out to see the comment\n",
    "c = ML_CLF()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10bb868-9c83-4c4b-8f37-4fc32dd66db5",
   "metadata": {},
   "source": [
    "**Task 3**: Let's change the classifier class and add a \"trial note\" to it, we wanna be able to store a comment like \"used KNN this time to try out \n",
    "...\".\n",
    "\n",
    "**Underlying problem:** We're using 2 special purpose classes to use 2 problems, throwing away the general purpose classes like dicts, arrays,... that are already well supplied with default functions.\n",
    "\n",
    "**Solution**: Let's use one of the cool general purposes classes to solve this, like the \"Map\". (Which in Python is a dict)\n",
    "\n",
    "While we're at this, we might as well separate code from data here as well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7cdcb716-6978-486f-a9e6-0f7987ac6292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML_Predictor(note='This is trial 1; using SVC', clf=SVC(decision_function_shape='ovo', probability=True))\n",
      "ML_Predictor(note='This is trial 2; using SVC with polyn. kernel', clf=SVC(decision_function_shape='ovo', kernel='poly', probability=True))\n",
      "pvector([('note', 'This is trial 1; using SVC'), ('clf', SVC(decision_function_shape='ovo', probability=True))])\n"
     ]
    }
   ],
   "source": [
    "### NEW FUN CODE ----------------------------------------------------------------\n",
    "class ML_Dataset(PRecord):\n",
    "    X = field()\n",
    "    y = field()\n",
    "    y_pred = field()\n",
    "    X_new = field()\n",
    "     \n",
    "def load_iris():\n",
    "    iris = datasets.load_iris()\n",
    "    r_1 = ML_Dataset()\n",
    "    r_2=r_1.set(X=iris[\"data\"][:,3:])\n",
    "    r_3=r_2.set(y=iris[\"target\"])\n",
    "    return r_3\n",
    "    \n",
    "class ML_Predictor(PRecord):\n",
    "    clf = field()\n",
    "    note = field()\n",
    "\n",
    "    \n",
    "def predict_stuff(m: ML_Predictor, d: ML_Dataset):\n",
    "    \n",
    "    m_2 = m.set(clf=m.clf.fit(r.X,r.y))\n",
    "    # Al right! Now we got...\n",
    "    # - m, as the initialized and unfitted CLF\n",
    "    # - m_2 as the fitted predictor. From the outside, not easy to distinguish...\n",
    "\n",
    "    d_2 = d.set(y_pred = m_2.clf.predict_proba(d.X_new))\n",
    "    return d_2\n",
    "\n",
    "### Our Program ----------------------------------------------------------------\n",
    "\n",
    "r = load_iris()\n",
    "\n",
    "r_2 = r.set(X_new = np.linspace(0,3,1000).reshape(-1,1))\n",
    "\n",
    "c = ML_Predictor(clf=svm.SVC(gamma='scale', decision_function_shape='ovo', probability=True), note=\"This is trial 1; using SVC\")\n",
    "c_2 = c.set(clf=svm.SVC(gamma='scale', decision_function_shape='ovo', probability=True, kernel='poly'), note=\"This is trial 2\\\n",
    "; using SVC with polyn. kernel\")\n",
    "print(c)\n",
    "print(c_2)\n",
    "print(c.items()) # we can use all the default cool functions on this generic Map!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
